{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import array\n",
    "from random import random\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB#57\n",
    "from sklearn.naive_bayes import GaussianNB#52\n",
    "from sklearn.naive_bayes import MultinomialNB#56\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovering Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_name(name):\n",
    "    df = pd.read_csv(name,usecols=[\"Label\"])\n",
    "    target_names=sorted(list(df[\"Label\"].unique()))\n",
    "    return target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(f_name): #this function creates a folder.\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"Tthe folder could not be created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_way(path,file_format):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                files_add.append(os.path.join(r, file))  \n",
    "    return files_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "altime=0\n",
    "#def most_frequent(List): \n",
    "#    return max(set(List), key = List.count) \n",
    "\n",
    "\n",
    " \n",
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    occurence_count={k: v for k, v in sorted(occurence_count.items(), key=lambda item: item[1],reverse=True)}\n",
    "    big=list(occurence_count.values())\n",
    "    big=big.count(big[0])\n",
    "    return list(occurence_count.keys())[np.random.randint(big)]\n",
    "\n",
    "\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "def create_exception(df): \n",
    "    exception_list=[]\n",
    "    dominant_mac=[]\n",
    "    for i in df['aggregated'].unique():\n",
    "        k=df[df['aggregated']==i]\n",
    "        for ii in ['MAC']:\n",
    "            hist = {}\n",
    "            for x in k[ii].values:\n",
    "                hist[x] = hist.get(x, 0) + 1\n",
    "            hist=dict(sorted(hist.items(), key=lambda item: item[1],reverse=True))\n",
    "            temp=next(iter(hist))\n",
    "            if temp not in dominant_mac:\n",
    "                dominant_mac.append(temp)\n",
    "            else:\n",
    "                exception_list.append(temp)\n",
    "    return exception_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merged(m_test,predict,step,mixed):\n",
    "    second=time.time()\n",
    "    mac_test=[]\n",
    "    for q in m_test.index:\n",
    "        mac_test.append(m_test[q])\n",
    "\n",
    "    d_list=sorted(list(m_test.unique()))\n",
    "    devices={}\n",
    "    for q in d_list:\n",
    "        devices[q]=[]    \n",
    "\n",
    "\n",
    "    new_y=[0]*len(m_test)\n",
    "\n",
    "    for q,qq in enumerate (mac_test):\n",
    "        devices[qq].append(q)\n",
    "    for q in devices:\n",
    "        a = [devices[q][j:j + step] for j in range(0, len(devices[q]), step)]  \n",
    "        for qq in a:\n",
    "            step_list=[]\n",
    "            for qqq in qq:\n",
    "                step_list.append(predict[qqq])\n",
    "            add=most_frequent(list(step_list))\n",
    "            for qqq in qq:\n",
    "                new_y[qqq]=add\n",
    "    results=pd.DataFrame(m_test)\n",
    "    results[\"aggregated\"]=new_y\n",
    "    results[\"normal\"]=predict\n",
    "    \n",
    "    #MIXED METHOD\n",
    "    if mixed:\n",
    "        exception=create_exception(results)\n",
    "        for q in exception:\n",
    "            results.loc[results.MAC == q, 'aggregated'] = results['normal']\n",
    "\n",
    "    return results[\"aggregated\"].values,time.time()-second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(altime,train_time,test_time,predict,y_test,class_based_results,i,cv,dname,ii):\n",
    "    precision=[]\n",
    "    recall=[]\n",
    "    f1=[]\n",
    "    accuracy=[]\n",
    "    total_time=[]\n",
    "    kappa=[]\n",
    "    accuracy_b=[]\n",
    "    \n",
    "    rc=sklearn.metrics.recall_score(y_test, predict,average= \"macro\")\n",
    "    pr=sklearn.metrics.precision_score(y_test, predict,average= \"macro\")\n",
    "    f_1=sklearn.metrics.f1_score(y_test, predict,average= \"macro\")        \n",
    "    report = classification_report(y_test, predict, target_names=target_names,output_dict=True)\n",
    "    cr = pd.DataFrame(report).transpose()\n",
    "    if class_based_results.empty:\n",
    "        class_based_results =cr\n",
    "    else:\n",
    "        class_based_results = class_based_results.add(cr, fill_value=0)\n",
    "    precision.append(float(pr))\n",
    "    recall.append(float(rc))\n",
    "    f1.append(float(f_1))\n",
    "    accuracy_b.append(balanced_accuracy_score( y_test,predict))\n",
    "    accuracy.append(accuracy_score(y_test, predict))\n",
    "\n",
    "    kappa.append(round(float(sklearn.metrics.cohen_kappa_score(y_test, predict, \n",
    "    labels=None, weights=None, sample_weight=None)),15))\n",
    "    print ('%-20s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-8s %-5s %-8s %-8s%-8s%-8s' % (dname,i,cv,ii[0:6],str(round(np.mean(accuracy),2)),str(round(np.mean(accuracy_b),2)),\n",
    "        str(round(np.mean(precision),2)), str(round(np.mean(recall),2)),str(round(np.mean(f1),4)), \n",
    "        str(round(np.mean(kappa),2)),str(round(np.mean(train_time),2)),str(round(np.mean(test_time),2)),str(round(np.mean(test_time)+np.mean(train_time),2)),str(round(np.mean(altime),2))))\n",
    "    lines=(str(dname)+\",\"+str(i)+\",\"+str(cv)+\",\"+str(ii)+\",\"+str(round(np.mean(accuracy),15))+\",\"+str(round(np.mean(accuracy_b),15))+\",\"+str(round(np.mean(precision),15))+\",\"+ str(round(np.mean(recall),15))+\",\"+str(round(np.mean(f1),15))+\",\"+str(round(np.mean(kappa),15))+\",\"+str(round(np.mean(train_time),15))+\",\"+str(round(np.mean(test_time),15))+\",\"+str(altime)+\"\\n\")\n",
    "    return lines,class_based_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML(loop1,loop2,output_csv,cols,step,mixed,dname):\n",
    "\n",
    "    ths = open(output_csv, \"w\")\n",
    "    ths.write(\"Dataset,T,CV,ML algorithm,Acc,b_Acc,Precision, Recall , F1-score, kappa ,tra-Time,test-Time,Al-Time\\n\")\n",
    "    \n",
    "\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    \n",
    "    for ii in ml_list:\n",
    "        print ('%-20s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-8s %-5s %-8s %-8s%-8s%-8s'%\n",
    "               (\"Dataset\",\"T\",\"CV\",\"ML alg\",\"Acc\",\"b_Acc\",\"Prec\", \"Rec\" , \"F1\", \"kap\" ,\"tra-T\",\"test-T\",\"total\",\"al-time\"))\n",
    "        class_based_results=pd.DataFrame()#\"\" #pd.DataFrame(0, index=np.arange((len(target_names)+3)), columns=[\"f1-score\",\"precision\",\"recall\",\"support\"])\n",
    "        cm=pd.DataFrame()\n",
    "        cv=0\n",
    "        if ii in [\"GB\",\"SVM\"]: #for slow algorithms.\n",
    "            repetition=25\n",
    "        else:\n",
    "            repetition=25\n",
    "        for i in range(repetition):\n",
    "\n",
    "\n",
    "\n",
    "            #TRAIN\n",
    "            df = pd.read_csv(loop1,usecols=cols)\n",
    "            m_train=df[\"eth.src\"]\n",
    "            del df[\"eth.src\"]\n",
    "            X_train =df[df.columns[0:-1]]\n",
    "            X_train=np.array(X_train)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y_train=df[df.columns[-1]].cat.codes  \n",
    "\n",
    "            #TEST\n",
    "            df = pd.read_csv(loop2,usecols=cols)\n",
    "            m_test=df[\"eth.src\"]\n",
    "            del df[\"eth.src\"]\n",
    "            X_test =df[df.columns[0:-1]]\n",
    "            X_test=np.array(X_test)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y_test=df[df.columns[-1]].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            results_y=[]\n",
    "            cv+=1\n",
    "            results_y.append(y_test)\n",
    "\n",
    "\n",
    "     \n",
    "   \n",
    "\n",
    "            #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary\n",
    "            second=time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            train_time=(float((time.time()-second)) )\n",
    "            second=time.time()\n",
    "            predict =clf.predict(X_test)\n",
    "            test_time=(float((time.time()-second)) )\n",
    "            if step==1:\n",
    "                altime=0\n",
    "                lines,class_based_results=score(altime,train_time,test_time,predict,y_test,class_based_results,i,cv,dname,ii)\n",
    "            else:\n",
    "                predict,altime=merged(m_test,predict,step,mixed)\n",
    "                lines,class_based_results=score(altime,train_time,test_time,predict,y_test,class_based_results,i,cv,dname,ii)\n",
    "            ths.write (lines)\n",
    "\n",
    "\n",
    "            df_cm = pd.DataFrame(confusion_matrix(y_test, predict))\n",
    "            if cm.empty:\n",
    "                cm =df_cm\n",
    "            else:\n",
    "                cm = cm.add(df_cm, fill_value=0)\n",
    "            \n",
    "        class_based_results=class_based_results/repetition\n",
    "        print(class_based_results)\n",
    "    \n",
    "        class_based_results.to_csv(output_csv.replace(\"Results\",\"CBR\"))\n",
    "        cm=cm//repetition\n",
    "        cm.to_csv(output_csv.replace(\"Results\",\"CM\"))\n",
    "        cmGraph=False\n",
    "        if cmGraph:\n",
    "            graph_name=output_csv+ii+\"_confusion matrix.pdf\"   \n",
    "            plt.figure(figsize = (40,28))\n",
    "            sns.heatmap(cm,xticklabels=target_names, yticklabels=target_names, annot=True, fmt='g')\n",
    "            plt.savefig(graph_name,bbox_inches='tight')#, dpi=400)\n",
    "            plt.show()\n",
    "            #print(cm)\n",
    "            print(\"\\n\\n\\n\")             \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    ths.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning applications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aalto Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature= feature= ['dstport',\n",
    "  'dstport_class',\n",
    "  'http.chat',\n",
    "  'http.notification',\n",
    "  'http.request.method',\n",
    "  'ip.flags.df',\n",
    "  'ip.len',\n",
    "  'ip.proto',\n",
    "  'ip.ttl',\n",
    "  'srcport',\n",
    "  'srcport_class',\n",
    "  'tcp.ack',\n",
    "  'tcp.analysis.ack_rtt',\n",
    "  'tcp.analysis.bytes_in_flight',\n",
    "  'tcp.analysis.initial_rtt',\n",
    "  'tcp.analysis.push_bytes_sent',\n",
    "  'tcp.completeness',\n",
    "  'tcp.dstport',\n",
    "  'tcp.flags',\n",
    "  'tcp.flags.push',\n",
    "  'tcp.flags.str',\n",
    "  'tcp.flags.syn',\n",
    "  'tcp.hdr_len',\n",
    "  'tcp.len',\n",
    "  'tcp.nxtseq',\n",
    "  'tcp.srcport',\n",
    "  'tcp.stream',\n",
    "  'tcp.time_delta',\n",
    "  'tcp.time_relative',\n",
    "  'tcp.window_size',\n",
    "  'tcp.window_size_scalefactor',\n",
    "  'tcp.window_size_value',\n",
    "  'tls.record.length',\n",
    "  'udp.checksum.status',\n",
    "  'udp.dstport',\n",
    "  'udp.srcport',\n",
    "  'udp.time_delta',\n",
    "  'udp.time_relative',\"eth.src\",\"Label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_list={\"DT\" :DecisionTreeClassifier()}\n",
    "\n",
    "\n",
    "#ml_list={\"RF\" :RandomForestClassifier()}\n",
    "dataset=\"./Results/\"\n",
    "folder(dataset)\n",
    "folder(\"CBR\")\n",
    "folder(\"CM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains=find_the_way(\"./DA\",\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset              T   CV  ML alg  Acc   b_Acc Prec  Rec   F1       kap   tra-T    test-T  total   al-time \n",
      "_GeMoDI              0   1   DT      0.73  0.59  0.7   0.59  0.6217   0.68  0.61     0.01    0.62    0.0     \n",
      "_GeMoDI              1   2   DT      0.73  0.59  0.71  0.59  0.6233   0.69  0.59     0.01    0.61    0.0     \n",
      "_GeMoDI              2   3   DT      0.73  0.59  0.7   0.59  0.6208   0.69  0.6      0.01    0.61    0.0     \n",
      "_GeMoDI              3   4   DT      0.73  0.6   0.71  0.6   0.6274   0.69  0.6      0.0     0.61    0.0     \n",
      "_GeMoDI              4   5   DT      0.73  0.59  0.71  0.59  0.6239   0.68  0.57     0.02    0.59    0.0     \n",
      "_GeMoDI              5   6   DT      0.73  0.59  0.71  0.59  0.6246   0.69  0.62     0.02    0.63    0.0     \n",
      "_GeMoDI              6   7   DT      0.73  0.59  0.7   0.59  0.6206   0.69  0.58     0.01    0.59    0.0     \n",
      "_GeMoDI              7   8   DT      0.73  0.6   0.71  0.6   0.6289   0.69  0.66     0.01    0.67    0.0     \n",
      "_GeMoDI              8   9   DT      0.73  0.59  0.71  0.59  0.6234   0.69  0.59     0.01    0.6     0.0     \n",
      "_GeMoDI              9   10  DT      0.72  0.59  0.71  0.59  0.6228   0.68  0.6      0.02    0.62    0.0     \n",
      "_GeMoDI              10  11  DT      0.73  0.59  0.7   0.59  0.6218   0.69  0.62     0.0     0.62    0.0     \n",
      "_GeMoDI              11  12  DT      0.73  0.59  0.71  0.59  0.6256   0.69  0.62     0.0     0.62    0.0     \n",
      "_GeMoDI              12  13  DT      0.73  0.59  0.7   0.59  0.6227   0.69  0.58     0.0     0.58    0.0     \n",
      "_GeMoDI              13  14  DT      0.73  0.59  0.71  0.59  0.6261   0.69  0.58     0.02    0.59    0.0     \n",
      "_GeMoDI              14  15  DT      0.73  0.59  0.7   0.59  0.6195   0.68  0.62     0.01    0.62    0.0     \n",
      "_GeMoDI              15  16  DT      0.73  0.59  0.7   0.59  0.62     0.68  0.58     0.01    0.59    0.0     \n",
      "_GeMoDI              16  17  DT      0.73  0.6   0.71  0.6   0.6277   0.69  0.6      0.02    0.62    0.0     \n",
      "_GeMoDI              17  18  DT      0.73  0.6   0.71  0.6   0.628    0.69  0.6      0.01    0.61    0.0     \n",
      "_GeMoDI              18  19  DT      0.73  0.59  0.71  0.59  0.6249   0.69  0.59     0.01    0.6     0.0     \n",
      "_GeMoDI              19  20  DT      0.73  0.59  0.71  0.59  0.6262   0.69  0.59     0.01    0.6     0.0     \n",
      "_GeMoDI              20  21  DT      0.73  0.59  0.71  0.59  0.6259   0.69  0.6      0.01    0.61    0.0     \n",
      "_GeMoDI              21  22  DT      0.73  0.59  0.7   0.59  0.6224   0.69  0.6      0.02    0.61    0.0     \n",
      "_GeMoDI              22  23  DT      0.73  0.59  0.7   0.59  0.6225   0.69  0.63     0.0     0.63    0.0     \n",
      "_GeMoDI              23  24  DT      0.73  0.59  0.71  0.59  0.6258   0.69  0.59     0.0     0.59    0.0     \n",
      "_GeMoDI              24  25  DT      0.72  0.59  0.7   0.59  0.6173   0.68  0.6      0.01    0.61    0.0     \n",
      "                   precision    recall  f1-score       support\n",
      "Aria                0.967768  0.732824  0.833979    131.000000\n",
      "D-LinkCam           0.741172  0.911987  0.817748   1273.000000\n",
      "D-LinkDayCam        0.886555  0.682848  0.771481    309.000000\n",
      "D-LinkDevice        0.564384  0.879103  0.687429   2230.000000\n",
      "D-LinkSensor        0.353873  0.330682  0.341788   1599.000000\n",
      "D-LinkSiren         0.306645  0.254180  0.277888   1574.000000\n",
      "D-LinkSwitch        0.626325  0.637341  0.631615   1670.000000\n",
      "D-LinkWaterSensor   0.467858  0.432417  0.449328   1688.000000\n",
      "EdimaxCam           0.842956  0.668161  0.745448    223.000000\n",
      "EdimaxPlug1101W     0.509027  0.618544  0.558453    261.000000\n",
      "EdimaxPlug2101W     0.629142  0.307872  0.413152    343.000000\n",
      "EdnetCam            0.928950  0.513274  0.661200    113.000000\n",
      "EdnetGateway        0.904494  0.646586  0.754098    249.000000\n",
      "HomeMaticPlug       1.000000  0.947977  0.973294    173.000000\n",
      "Hue-Device          0.989653  0.974837  0.982189   8053.000000\n",
      "Lightify            0.980076  0.915780  0.946838   1128.000000\n",
      "MAXGateway          1.000000  0.837500  0.911565    160.000000\n",
      "SmarterCoffee       0.500000  0.020833  0.040000     48.000000\n",
      "TP-LinkPlugHS100    0.526274  0.410166  0.460784    181.000000\n",
      "TP-LinkPlugHS110    0.524989  0.434066  0.474998    182.000000\n",
      "WeMoInsightSwitch   0.612684  0.568577  0.589793   1567.000000\n",
      "WeMoLink            0.798534  0.852260  0.824515   1889.000000\n",
      "WeMoSwitch          0.521579  0.394554  0.449243   1021.000000\n",
      "Withings            1.000000  0.748792  0.856354    207.000000\n",
      "iKettle2            0.444444  0.083333  0.140351     48.000000\n",
      "accuracy            0.728907  0.728907  0.728907      0.728907\n",
      "macro avg           0.705095  0.592180  0.623741  26320.000000\n",
      "weighted avg        0.729720  0.728907  0.722757  26320.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test='Validation_GeMoDI.csv'\n",
    "target_names=target_name(test)\n",
    "mixed=False\n",
    "step=1\n",
    "sayac=1\n",
    "for train in [\"Train_GeMoDI.csv\"]:\n",
    "    dataset=\"./Results/\"\n",
    "    output_csv=dataset+train\n",
    "    output_csv=output_csv.replace(\".csv\",f\"_{step}.csv\")\n",
    "    output_csv=output_csv.replace(\".csv\",\"_ML.csv\")\n",
    "    ML(train,test,output_csv,feature,step,mixed,train[5:-4])   \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
