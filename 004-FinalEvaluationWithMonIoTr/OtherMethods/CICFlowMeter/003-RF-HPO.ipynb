{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is where the datasets to be used in the Hyper parameter detection work are generated. For example, smaller (to combat slowness) but non-intersecting training and test files from a single dataset without breaking the isolaton are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_file=\"./csvs/uk.csv\"\n",
    "df=pd.read_csv(sample_file)\n",
    "train = df.groupby('Label').apply(lambda x: x.sample(n=min(1000, (len(x)//2-1))))\n",
    "train = train.droplevel('Label')\n",
    "df = df.drop(train.index)\n",
    "test = df.groupby('Label').apply(lambda x: x.sample(n=min(1000, (len(x)//2-1))))\n",
    "test = test.droplevel('Label')\n",
    "\n",
    "train.to_csv(\"trainHPO.csv\",index=False)\n",
    "test.to_csv(\"testHPO.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_add=['csvs\\\\AD-S1.csv', 'csvs\\\\AD-S2.csv', 'csvs\\\\DI-S1.csv', 'csvs\\\\DI-S2.csv']\n",
    "#for i in files_add:\n",
    "    #df=pd.read_csv(i)\n",
    "    #df = df.groupby('Label').apply(lambda x: x.sample(n=min(1000, len(x))))\n",
    "    #df = df.droplevel('Label')\n",
    "    #name=i.replace(\"csvs\",\"small\")\n",
    "   # df.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#with open('GA_output_ET.json', 'r') as fp:\n",
    "    #feature_list = json.load(fp)\n",
    "\n",
    "feature_list =['ACK Flag Cnt',\n",
    " 'Active Max',\n",
    " 'Active Mean',\n",
    " 'Active Std',\n",
    " 'Bwd Header Len',\n",
    " 'Bwd IAT Min',\n",
    " 'Bwd IAT Tot',\n",
    " 'Bwd Pkt Len Max',\n",
    " 'Bwd Pkt Len Mean',\n",
    " 'Bwd Pkt Len Min',\n",
    " 'FIN Flag Cnt',\n",
    " 'Flow Byts/s',\n",
    " 'Flow Duration',\n",
    " 'Flow IAT Max',\n",
    " 'Flow IAT Mean',\n",
    " 'Flow IAT Std',\n",
    " 'Fwd IAT Mean',\n",
    " 'Fwd IAT Min',\n",
    " 'Fwd IAT Std',\n",
    " 'Fwd IAT Tot',\n",
    " 'Fwd Pkt Len Max',\n",
    " 'Fwd Pkt Len Std',\n",
    " 'Fwd Pkts/s',\n",
    " 'Idle Max',\n",
    " 'Idle Mean',\n",
    " 'Idle Std',\n",
    " 'Init Bwd Win Byts',\n",
    " 'Pkt Len Max',\n",
    " 'Pkt Len Min',\n",
    " 'Pkt Len Var',\n",
    " 'Pkt Size Avg',\n",
    " 'Protocol',\n",
    " 'Src Port',\n",
    " 'Subflow Bwd Byts',\n",
    " 'Tot Fwd Pkts',\n",
    " 'TotLen Bwd Pkts',\n",
    " 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list={\"HPO\":['./trainHPO.csv','./testHPO.csv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(model, params, x_train, y_train):\n",
    "    #grid = GridSearchCV(model, params, cv = ps, n_jobs = -1, scoring = score, verbose = 0, refit = False)\n",
    "    grid =RandomizedSearchCV(model, param_grid, cv=ps,scoring = 'f1_macro')\n",
    "    grid.fit(x_train, y_train)\n",
    "    return (grid.best_params_, round(grid.best_score_,8),grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))  \n",
    "            \n",
    "    return files_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "HYPERPARAMETERS                     F1 Score             Time     No      \n",
      "default                             0.8468322162239645   7.07     0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [46:19<00:00, 277.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bootst    criter      max_depth    max_features    min_samp_split    n_estimators        F1          Std     Time    No  Attack\n",
      "--  --------  --------  -----------  --------------  ----------------  --------------  --------  -----------  -------  ----  --------\n",
      " 0  False     gini               17              10                 7             188  0.854352  0.000331999  296.484     4  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print ('%-35s %-20s %-8s %-8s' % (\"HYPERPARAMETERS\",\"F1 Score\", \"Time\", \"No\"))\n",
    "\n",
    "\n",
    "\n",
    "    # use a full grid over all parameters\n",
    "    param_grid = {\"max_depth\":np.linspace(1, 32, 32, endpoint=True).astype(int),\n",
    "                  \"n_estimators\" : sp_randint(1, 200),\n",
    "                  \"max_features\": sp_randint(1, 11),\n",
    "                  \"min_samples_split\":sp_randint(2, 11),\n",
    "                  \"bootstrap\": [True, False],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=RandomForestClassifier()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(RandomForestClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"RF_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
