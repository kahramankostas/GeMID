{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_add=['csvs\\\\AD-S1.csv', 'csvs\\\\AD-S2.csv', 'csvs\\\\DI-S1.csv', 'csvs\\\\DI-S2.csv']\n",
    "for i in files_add:\n",
    "    df=pd.read_csv(i)\n",
    "    df = df.groupby('Label').apply(lambda x: x.sample(n=min(1000, len(x))))\n",
    "    df = df.droplevel('Label')\n",
    "    name=i.replace(\"csvs\",\"small\")\n",
    "    df.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randInt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#with open('GA_output_ET.json', 'r') as fp:\n",
    "    #feature_list = json.load(fp)\n",
    "\n",
    "feature_list =col= ['pck_size', 'Ether_type', 'LLC_ctrl', 'EAPOL_version', 'EAPOL_type', 'IP_ihl', 'IP_tos', 'IP_len', 'IP_flags', 'IP_DF', 'IP_ttl', 'IP_options', 'ICMP_code', 'TCP_dataofs', 'TCP_FIN', 'TCP_ACK', 'TCP_window', 'UDP_len', 'DHCP_options', 'BOOTP_hlen', 'BOOTP_flags', 'BOOTP_sname', 'BOOTP_file', 'BOOTP_options', 'DNS_qr', 'DNS_rd', 'DNS_qdcount', 'dport_class', 'payload_bytes', 'entropy',\n",
    "#\"MAC\",\n",
    "'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list={\"HPO\":['./small/AD-S1.csv','./small/AD-S2.csv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(model, params, x_train, y_train):\n",
    "    #grid = GridSearchCV(model, params, cv = ps, n_jobs = -1, scoring = score, verbose = 0, refit = False)\n",
    "    grid =RandomizedSearchCV(model, param_grid, cv=ps,scoring = 'f1_macro')\n",
    "    grid.fit(x_train, y_train)\n",
    "    return (grid.best_params_, round(grid.best_score_,8),grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))  \n",
    "            \n",
    "    return files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "HYPERPARAMETERS                     F1 Score             Time     No      \n",
      "default                             0.9363171592880518   2.238    24      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:49<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    criterion      max_depth    max_features    min_samples_split        F1        Std    Time    No  Attack\n",
      "--  -----------  -----------  --------------  -------------------  --------  ---------  ------  ----  --------\n",
      " 0  entropy               19              24                    5  0.949974  0.0232168   1.776    25  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['criterion', 'max_depth', 'max_features', 'min_samples_split', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "    print ('%-35s %-20s %-8s %-8s' % (\"HYPERPARAMETERS\",\"F1 Score\", \"Time\", \"No\"))\n",
    "\n",
    "    nfolds=10\n",
    "    param_grid = { 'criterion':['gini','entropy'],\n",
    "                      \"max_depth\":np.linspace(1, 32, 32, endpoint=True).astype(int),\n",
    "                     \"min_samples_split\": sp_randint(2,10),#uniform(0.1,1 ),\n",
    "                        # \"min_samples_leafs\" : np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "                        \"max_features\" : sp_randint(1,X_train.shape[1])}\n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=DecisionTreeClassifier()\n",
    "    for ii in range(25):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(50)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(DecisionTreeClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(10):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"DT_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['criterion', 'max_depth', 'max_features', 'min_samples_split', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "HYPERPARAMETERS                     F1 Score             Time     No      \n",
      "default                             0.9311447968481307   4.268    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [14:41<00:00, 88.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bootst    criter      max_depth    max_features    min_samp_split    n_estimators       F1          Std    Time    No  Attack\n",
      "--  --------  --------  -----------  --------------  ----------------  --------------  -------  -----------  ------  ----  --------\n",
      " 0  False     gini               31              10                 2             136  0.93875  0.000216566  92.819     2  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print ('%-35s %-20s %-8s %-8s' % (\"HYPERPARAMETERS\",\"F1 Score\", \"Time\", \"No\"))\n",
    "\n",
    "\n",
    "\n",
    "    # use a full grid over all parameters\n",
    "    param_grid = {\"max_depth\":np.linspace(1, 32, 32, endpoint=True).astype(int),\n",
    "                  \"n_estimators\" : sp_randint(1, 200),\n",
    "                  \"max_features\": sp_randint(1, 11),\n",
    "                  \"min_samples_split\":sp_randint(2, 11),\n",
    "                  \"bootstrap\": [True, False],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=RandomForestClassifier()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(RandomForestClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"RF_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.9344788983729851   6.993    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▏                                                                | 1/5 [16:11<1:04:46, 971.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1500, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.15}       0.9358862878641536   971.699  0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [30:43<45:38, 912.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1100, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.2}       0.9351376377620468   871.865  1       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [43:16<27:59, 839.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1100, 'min_child_weight': 2, 'max_depth': 3, 'learning_rate': 0.1}        0.9352528774114784   752.871  2       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [58:47<14:35, 875.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1100, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.2}       0.9351376377620468   931.143  3       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [1:15:32<00:00, 906.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1500, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.2}        0.9352114409548425   1004.847 4       \n",
      "      n_estimators    min_child_weight    max_depth    learning_rate        F1    Std      Time    No  Attack\n",
      "--  --------------  ------------------  -----------  ---------------  --------  -----  --------  ----  --------\n",
      " 0            1500                   1            3             0.15  0.935886      0   971.699     0  HPO\n",
      " 1            1100                   1           10             0.2   0.935138      0   871.865     1  HPO\n",
      " 2            1100                   2            3             0.1   0.935253      0   752.871     2  HPO\n",
      " 3            1100                   1           10             0.2   0.935138      0   931.143     3  HPO\n",
      " 4            1500                   1            5             0.2   0.935211      0  1004.85      4  HPO\n",
      "      n_estimators   min_child_weight    max_depth     learning_rate     F1     Std     Time     No    Attack\n",
      "--  --------------  -----------  ---------------  ------------------  --------  -----  -------  ----  --------\n",
      " 0            1500            1                3                0.15  0.935886      0  971.699     0  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "lines=[['n_estimators', 'min_child_weight', 'max_depth','learning_rate', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "\n",
    "\n",
    "    param_grid =   {\n",
    "    'n_estimators': [100, 500, 900, 1100, 1500],\n",
    "    'max_depth': [2, 3, 5, 10, 15],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.20],\n",
    "    'min_child_weight': [1, 2, 3, 4]\n",
    "    }\n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=xgboost.XGBClassifier()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(5)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(xgboost.XGBClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"XGB_HPO.csv\",index=False)\n",
    "\n",
    "\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "final_parametres=[['n_estimators', 'min_child_weight', 'max_depth','learning_rate', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.9063386885636363   54.28    24      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:55<00:00, 23.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    algorithm      leaf_size    n_neighbors  weights          F1          Std    Time    No  Attack\n",
      "--  -----------  -----------  -------------  ---------  --------  -----------  ------  ----  --------\n",
      " 0  ball_tree             35             13  distance   0.926902  1.11022e-16  23.693     3  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['algorithm', 'leaf_size', 'n_neighbors', 'weights', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "\n",
    "    # use a full grid over all parameters\n",
    "    param_grid = {\"n_neighbors\" : sp_randint(1,64) ,  \n",
    "                 \"leaf_size\": sp_randint(1,50) , \n",
    "                  \"algorithm\" : [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                  \"weights\" : [\"uniform\", \"distance\"]}\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=KNeighborsClassifier()\n",
    "    for ii in range(25):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(KNeighborsClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"knn_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['algorithm', 'leaf_size', 'n_neighbors', 'weights', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"n_neighbors\"].min()\n",
    "    df=df[df[\"n_neighbors\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.3793524072571346   0.231    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:34<00:00,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      var_smoothing        F1    Std    Time    No  Attack\n",
      "--  ---------------  --------  -----  ------  ----  --------\n",
      " 0      4.32876e-06  0.387475      0   3.396     0  HPO\n",
      " 1      3.51119e-06  0.38755       0   2.917     1  HPO\n",
      " 2      2.31013e-06  0.390945      0   3.319     2  HPO\n",
      " 3      3.51119e-07  0.387169      0   3.322     3  HPO\n",
      " 4      4.32876e-06  0.387475      0   3.352     4  HPO\n",
      " 5      2.84804e-06  0.389813      0   3.488     5  HPO\n",
      " 6      1.23285e-07  0.38687       0   3.65      6  HPO\n",
      " 7      2.31013e-06  0.390945      0   4.061     7  HPO\n",
      " 8      5.3367e-08   0.384993      0   3.966     8  HPO\n",
      " 9      2.84804e-06  0.389813      0   3.449     9  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['var_smoothing', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    second=time()\n",
    "\n",
    "    param_grid = {\n",
    "        'var_smoothing': np.logspace(0,-9, num=100),\n",
    "    }\n",
    "\n",
    " \n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=GaussianNB()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(GaussianNB(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"NB_HPO.csv\",index=False)\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      var_smoothing        F1    Std    Time    No  Attack\n",
      "--  ---------------  --------  -----  ------  ----  --------\n",
      " 0      2.31013e-06  0.390945      0   3.319     2  HPO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_parametres=[[\"var_smoothing\",\"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.3154644326994476   2.692    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [1:35:54<00:00, 575.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             C  penalty    Solver           F1          Std      Time    No  Attack\n",
      "--  ----------  ---------  ---------  --------  -----------  --------  ----  --------\n",
      " 0  64.1099     l1         liblinear  0.719177  0.00116022    853.741     0  HPO\n",
      " 1   0.0448205  l2         liblinear  0.659584  0              97.357     1  HPO\n",
      " 2   0.0117644  l2         liblinear  0.627227  0             433.361     2  HPO\n",
      " 3   0.0661555  l2         liblinear  0.624058  0             266.23      3  HPO\n",
      " 4   6.55241    l1         liblinear  0.718797  0.0020438    1184.8       4  HPO\n",
      " 5   0.607881   l1         liblinear  0.71929   0.00254251    795.773     5  HPO\n",
      " 6   0.689136   l1         liblinear  0.720897  0.000204922   904.417     6  HPO\n",
      " 7   0.0262128  l2         liblinear  0.647697  0              83.956     7  HPO\n",
      " 8   6.60674    l2         liblinear  0.645614  0             284.574     8  HPO\n",
      " 9  38.9564     l1         liblinear  0.716895  0.00253348    850.327     9  HPO\n",
      "           C  penalty    Solver           F1          Std     Time    No  Attack\n",
      "--  --------  ---------  ---------  --------  -----------  -------  ----  --------\n",
      " 0  0.689136  l1         liblinear  0.720897  0.000204922  904.417     6  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lines=[[\"C\",'penalty','Solver',  \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    second=time()\n",
    "\n",
    "    param_grid = {\n",
    "     'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'C' : loguniform(1e-5, 100)\n",
    "        }\n",
    "    \n",
    "\n",
    " \n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=LogisticRegression()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(LogisticRegression(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"LR_HPO.csv\",index=False)\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "final_parametres=[[\"C\",'penalty','Solver',  \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.3135934147771435   95.391   0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                        | 1/10 [15:30<2:19:30, 930.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 10}                                                                      0.9475068782849669   930.073  0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████                                                                | 2/10 [31:13<2:05:04, 938.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 10}                                                                      0.9475068782849669   943.605  1       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████                                                        | 3/10 [45:02<1:43:36, 888.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 1}                                                                       0.945385253735041    828.667  2       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████                                                | 4/10 [58:35<1:25:51, 858.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.1, 'C': 1}                                                                     0.907331186555255    813.234  3       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████                                       | 5/10 [1:14:57<1:15:15, 903.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 10}                                                                      0.9475068782849669   981.837  4       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████                                | 6/10 [1:28:16<57:51, 867.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 1}                                                                       0.945385253735041    799.417  5       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████                        | 7/10 [1:43:39<44:17, 885.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 10}                                                                      0.9475068782849669   922.798  6       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████                | 8/10 [1:59:07<29:58, 899.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 10}                                                                      0.9475068782849669   927.578  7       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████        | 9/10 [2:12:42<14:32, 872.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 10}                                                                      0.9475068782849669   815.216  8       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [2:32:06<00:00, 912.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.1, 'C': 1}                                                                     0.907331186555255    1164.023 9       \n",
      "      gamma    C        F1    Std      Time    No  Attack\n",
      "--  -------  ---  --------  -----  --------  ----  --------\n",
      " 0      1     10  0.947507      0   930.073     0  HPO\n",
      " 1      1     10  0.947507      0   943.605     1  HPO\n",
      " 2      1      1  0.945385      0   828.667     2  HPO\n",
      " 3      0.1    1  0.907331      0   813.234     3  HPO\n",
      " 4      1     10  0.947507      0   981.837     4  HPO\n",
      " 5      1      1  0.945385      0   799.417     5  HPO\n",
      " 6      1     10  0.947507      0   922.798     6  HPO\n",
      " 7      1     10  0.947507      0   927.578     7  HPO\n",
      " 8      1     10  0.947507      0   815.216     8  HPO\n",
      " 9      0.1    1  0.907331      0  1164.02      9  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[[ 'gamma','C', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "\n",
    "\n",
    "    param_grid =  {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma' : [0.001, 0.01, 0.1, 1]}  \n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=svm.SVC()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(svm.SVC(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(1):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"svm_HPO.csv\",index=False)\n",
    "\n",
    "\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           C  penalty    Solver                    F1             Std     Time  No    Attack\n",
      "--  --------  ---------  ------------------  --------  --------------  -------  ----  --------\n",
      " 0  0.689136  l1         liblinear           0.720897     0.000204922  904.417  6     HPO\n",
      " 1  0.1       10         0.914818562492174   0         1032.27           0      HPO\n",
      " 2  1         10         0.9475068782849669  0          930.073          0      HPO\n"
     ]
    }
   ],
   "source": [
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown /s /t 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown -a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
