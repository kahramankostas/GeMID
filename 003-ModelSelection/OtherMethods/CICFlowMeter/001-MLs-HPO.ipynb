{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_add=['csvs\\\\AD-S1.csv', 'csvs\\\\AD-S2.csv', 'csvs\\\\DI-S1.csv', 'csvs\\\\DI-S2.csv']\n",
    "#for i in files_add:\n",
    "    #df=pd.read_csv(i)\n",
    "    #df = df.groupby('Label').apply(lambda x: x.sample(n=min(1000, len(x))))\n",
    "    #df = df.droplevel('Label')\n",
    "    #name=i.replace(\"csvs\",\"small\")\n",
    "    #df.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randInt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#with open('GA_output_ET.json', 'r') as fp:\n",
    "    #feature_list = json.load(fp)\n",
    "\n",
    "# Veri yükleme\n",
    "feature_list =['ACK Flag Cnt',\n",
    " 'Active Max',\n",
    " 'Active Mean',\n",
    " 'Active Std',\n",
    " 'Bwd Header Len',\n",
    " 'Bwd IAT Min',\n",
    " 'Bwd IAT Tot',\n",
    " 'Bwd Pkt Len Max',\n",
    " 'Bwd Pkt Len Mean',\n",
    " 'Bwd Pkt Len Min',\n",
    " 'FIN Flag Cnt',\n",
    " 'Flow Byts/s',\n",
    " 'Flow Duration',\n",
    " 'Flow IAT Max',\n",
    " 'Flow IAT Mean',\n",
    " 'Flow IAT Std',\n",
    " 'Fwd IAT Mean',\n",
    " 'Fwd IAT Min',\n",
    " 'Fwd IAT Std',\n",
    " 'Fwd IAT Tot',\n",
    " 'Fwd Pkt Len Max',\n",
    " 'Fwd Pkt Len Std',\n",
    " 'Fwd Pkts/s',\n",
    " 'Idle Max',\n",
    " 'Idle Mean',\n",
    " 'Idle Std',\n",
    " 'Init Bwd Win Byts',\n",
    " 'Pkt Len Max',\n",
    " 'Pkt Len Min',\n",
    " 'Pkt Len Var',\n",
    " 'Pkt Size Avg',\n",
    " 'Protocol',\n",
    " 'Src Port',\n",
    " 'Subflow Bwd Byts',\n",
    " 'Tot Fwd Pkts',\n",
    " 'TotLen Bwd Pkts',\n",
    " 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list={\"HPO\":['./small/AD-S1.csv','./small/AD-S2.csv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(model, params, x_train, y_train):\n",
    "    #grid = GridSearchCV(model, params, cv = ps, n_jobs = -1, scoring = score, verbose = 0, refit = False)\n",
    "    grid =RandomizedSearchCV(model, param_grid, cv=ps,scoring = 'f1_macro')\n",
    "    grid.fit(x_train, y_train)\n",
    "    return (grid.best_params_, round(grid.best_score_,8),grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))  \n",
    "            \n",
    "    return files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "HYPERPARAMETERS                     F1 Score             Time     No      \n",
      "default                             0.7148072650521422   10.922   24      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [19:24<00:00, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    criterion      max_depth    max_features    min_samples_split        F1        Std    Time    No  Attack\n",
      "--  -----------  -----------  --------------  -------------------  --------  ---------  ------  ----  --------\n",
      " 0  entropy               18               6                    6  0.845152  0.0111468   6.566    26  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['criterion', 'max_depth', 'max_features', 'min_samples_split', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "    print ('%-35s %-20s %-8s %-8s' % (\"HYPERPARAMETERS\",\"F1 Score\", \"Time\", \"No\"))\n",
    "\n",
    "    nfolds=10\n",
    "    param_grid = { 'criterion':['gini','entropy'],\n",
    "                      \"max_depth\":np.linspace(1, 32, 32, endpoint=True).astype(int),\n",
    "                     \"min_samples_split\": sp_randint(2,10),#uniform(0.1,1 ),\n",
    "                        # \"min_samples_leafs\" : np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "                        \"max_features\" : sp_randint(1,X_train.shape[1])}\n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=DecisionTreeClassifier()\n",
    "    for ii in range(25):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(50)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(DecisionTreeClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(10):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"DT_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['criterion', 'max_depth', 'max_features', 'min_samples_split', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "HYPERPARAMETERS                     F1 Score             Time     No      \n",
      "default                             0.8722219187014226   19.5     0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [54:31<00:00, 327.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bootst    criter      max_depth    max_features    min_samp_split    n_estimators        F1         Std     Time    No  Attack\n",
      "--  --------  --------  -----------  --------------  ----------------  --------------  --------  ----------  -------  ----  --------\n",
      " 0  False     gini               29               6                 5              88  0.875883  0.00459075  585.046     0  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print ('%-35s %-20s %-8s %-8s' % (\"HYPERPARAMETERS\",\"F1 Score\", \"Time\", \"No\"))\n",
    "\n",
    "\n",
    "\n",
    "    # use a full grid over all parameters\n",
    "    param_grid = {\"max_depth\":np.linspace(1, 32, 32, endpoint=True).astype(int),\n",
    "                  \"n_estimators\" : sp_randint(1, 200),\n",
    "                  \"max_features\": sp_randint(1, 11),\n",
    "                  \"min_samples_split\":sp_randint(2, 11),\n",
    "                  \"bootstrap\": [True, False],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=RandomForestClassifier()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(RandomForestClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"RF_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.8380876164854576   7.522    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [08:54<35:39, 534.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_child_weight': 4, 'max_depth': 10, 'learning_rate': 0.2}        0.8507523905009048   534.781  0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [20:28<31:25, 628.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 900, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.2}         0.8554285893661022   693.901  1       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [38:28<27:49, 834.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1500, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.05}       0.8527729491504903   1079.811 2       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [54:52<14:53, 893.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1100, 'min_child_weight': 1, 'max_depth': 10, 'learning_rate': 0.1}       0.8560750211059862   983.621  3       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [1:08:12<00:00, 818.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1100, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.15}       0.8574823057693368   800.487  4       \n",
      "      n_estimators    min_child_weight    max_depth    learning_rate        F1          Std      Time    No  Attack\n",
      "--  --------------  ------------------  -----------  ---------------  --------  -----------  --------  ----  --------\n",
      " 0             100                   4           10             0.2   0.850752  0             534.789     0  HPO\n",
      " 1             900                   3            3             0.2   0.855429  0             693.901     1  HPO\n",
      " 2            1500                   1            5             0.05  0.852773  1.11022e-16  1079.81      2  HPO\n",
      " 3            1100                   1           10             0.1   0.856075  0             983.621     3  HPO\n",
      " 4            1100                   1            3             0.15  0.857482  1.11022e-16   800.487     4  HPO\n",
      "      n_estimators   min_child_weight    max_depth       learning_rate          F1     Std           Time     No    Attack\n",
      "--  --------------     -----------      ---------------  ----------------  --------  -----------   -------    ----  --------\n",
      " 0            1100            1                3                0.15       0.857482  1.11022e-16   800.487     4     HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "lines=[['n_estimators', 'min_child_weight', 'max_depth','learning_rate', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "\n",
    "\n",
    "    param_grid =   {\n",
    "    'n_estimators': [100, 500, 900, 1100, 1500],\n",
    "    'max_depth': [2, 3, 5, 10, 15],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.20],\n",
    "    'min_child_weight': [1, 2, 3, 4]\n",
    "    }\n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=xgboost.XGBClassifier()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(5)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(xgboost.XGBClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"XGB_HPO.csv\",index=False)\n",
    "\n",
    "\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "final_parametres=[['n_estimators', 'min_child_weight', 'max_depth','learning_rate', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      n_estimators   min_child_weight    max_depth       learning_rate          F1     Std           Time     No    Attack\n",
      "--  --------------     -----------     ---------------  ------------------  --------  -----------  -------  ----  --------\n",
      " 0            1100            1                3                0.15        0.857482  1.11022e-16  800.487     4    HPO\n"
     ]
    }
   ],
   "source": [
    "final_parametres=[['n_estimators', 'min_child_weight', 'max_depth','learning_rate', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.8156929531305663   201.98   24      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [11:38<00:00, 69.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    algorithm      leaf_size    n_neighbors  weights          F1    Std    Time    No  Attack\n",
      "--  -----------  -----------  -------------  ---------  --------  -----  ------  ----  --------\n",
      " 0  ball_tree             44              4  distance   0.828002      0  77.511     5  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['algorithm', 'leaf_size', 'n_neighbors', 'weights', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "\n",
    "    # use a full grid over all parameters\n",
    "    param_grid = {\"n_neighbors\" : sp_randint(1,64) ,  \n",
    "                 \"leaf_size\": sp_randint(1,50) , \n",
    "                  \"algorithm\" : [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                  \"weights\" : [\"uniform\", \"distance\"]}\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=KNeighborsClassifier()\n",
    "    for ii in range(25):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(KNeighborsClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"knn_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['algorithm', 'leaf_size', 'n_neighbors', 'weights', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"n_neighbors\"].min()\n",
    "    df=df[df[\"n_neighbors\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.3014226749707934   0.158    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:24<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      var_smoothing        F1    Std    Time    No  Attack\n",
      "--  ---------------  --------  -----  ------  ----  --------\n",
      " 0      8.11131e-09  0.325063      0   2.499     0  HPO\n",
      " 1      5.3367e-08   0.312354      0   2.401     1  HPO\n",
      " 2      4.32876e-09  0.320853      0   2.481     2  HPO\n",
      " 3      1e-09        0.301423      0   2.432     3  HPO\n",
      " 4      1.51991e-09  0.300712      0   2.441     4  HPO\n",
      " 5      1.87382e-08  0.324712      0   2.432     5  HPO\n",
      " 6      1.87382e-08  0.324712      0   2.441     6  HPO\n",
      " 7      1.87382e-08  0.324712      0   2.534     7  HPO\n",
      " 8      8.11131e-09  0.325063      0   2.432     8  HPO\n",
      " 9      1.87382e-08  0.324712      0   2.492     9  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['var_smoothing', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    second=time()\n",
    "\n",
    "    param_grid = {\n",
    "        'var_smoothing': np.logspace(0,-9, num=100),\n",
    "    }\n",
    "\n",
    " \n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=GaussianNB()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(GaussianNB(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"NB_HPO.csv\",index=False)\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      var_smoothing        F1    Std    Time    No  Attack\n",
      "--  ---------------  --------  -----  ------  ----  --------\n",
      " 0      8.11131e-09  0.325063      0   2.499     0  HPO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_parametres=[[\"var_smoothing\",\"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.35923106781065345  2.944    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 10/10 [5:31:16<00:00, 1987.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               C  penalty    Solver           F1         Std      Time    No  Attack\n",
      "--  ------------  ---------  ---------  --------  ----------  --------  ----  --------\n",
      " 0   0.00696236   l1         liblinear  0.636956  0.00453674  2652         0  HPO\n",
      " 1   0.10342      l1         liblinear  0.655253  0.00236439  2341.84      1  HPO\n",
      " 2   2.75128e-05  l1         liblinear  0.48038   0.0011836   2053.37      2  HPO\n",
      " 3   0.0012905    l2         newton-cg  0.469411  0            967.444     3  HPO\n",
      " 4   0.0489321    l1         liblinear  0.653389  0.00374719  2477.68      4  HPO\n",
      " 5   0.192761     l2         liblinear  0.390436  0            162.061     5  HPO\n",
      " 6  46.6013       l2         newton-cg  0.470346  0           1093.6       6  HPO\n",
      " 7   0.00722457   l1         liblinear  0.645749  0.0039773   2907.23      7  HPO\n",
      " 8   3.44031      l1         liblinear  0.648091  0.00153363  2269.58      8  HPO\n",
      " 9   0.000116879  l1         liblinear  0.52401   0.00074709  2951.54      9  HPO\n",
      "          C  penalty    Solver           F1         Std     Time    No  Attack\n",
      "--  -------  ---------  ---------  --------  ----------  -------  ----  --------\n",
      " 0  0.10342  l1         liblinear  0.655253  0.00236439  2341.84     1  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lines=[[\"C\",'penalty','Solver',  \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    second=time()\n",
    "\n",
    "    param_grid = {\n",
    "     'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'C' : loguniform(1e-5, 100)\n",
    "        }\n",
    "    \n",
    "\n",
    " \n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=LogisticRegression()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(LogisticRegression(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"LR_HPO.csv\",index=False)\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "final_parametres=[[\"C\",'penalty','Solver',  \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.41656694793459564  59.141   0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [26:56<00:00, 1616.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.001, 'C': 1}                                                                   0.10989375413855715  1616.025 0       \n",
      "      gamma    C        F1    Std     Time    No  Attack\n",
      "--  -------  ---  --------  -----  -------  ----  --------\n",
      " 0    0.001    1  0.109894      0  1616.03     0  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[[ 'gamma','C', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "\n",
    "\n",
    "    param_grid =  {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma' : [0.001, 0.01, 0.1, 1]}  \n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=svm.SVC()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(1)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(svm.SVC(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(1):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"svm_HPO.csv\",index=False)\n",
    "\n",
    "\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown /s /t 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
