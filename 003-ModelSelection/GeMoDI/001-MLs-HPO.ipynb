{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from time import time\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_add=['csvs\\\\AD-S1.csv', 'csvs\\\\AD-S2.csv', 'csvs\\\\DI-S1.csv', 'csvs\\\\DI-S2.csv']\n",
    "#for i in files_add:\n",
    "    #df=pd.read_csv(i)\n",
    "    #df = df.groupby('Label').apply(lambda x: x.sample(n=min(1000, len(x))))\n",
    "    #df = df.droplevel('Label')\n",
    "    #name=i.replace(\"csvs\",\"small\")\n",
    "   # df.to_csv(name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randInt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#with open('GA_output_ET.json', 'r') as fp:\n",
    "    #feature_list = json.load(fp)\n",
    "\n",
    "feature_list =['dstport',\n",
    "  'dstport',\n",
    "  'dstport_class',\n",
    "  'http.chat',\n",
    "  'http.notification',\n",
    "  'http.request.method',\n",
    "  'ip.flags.df',\n",
    "  'ip.len',\n",
    "  'ip.proto',\n",
    "  'ip.ttl',\n",
    "  'srcport',\n",
    "  'srcport_class',\n",
    "  'tcp.ack',\n",
    "  'tcp.analysis.ack_rtt',\n",
    "  'tcp.analysis.bytes_in_flight',\n",
    "  'tcp.analysis.initial_rtt',\n",
    "  'tcp.analysis.push_bytes_sent',\n",
    "  'tcp.completeness',\n",
    "  'tcp.dstport',\n",
    "  'tcp.flags',\n",
    "  'tcp.flags.push',\n",
    "  'tcp.flags.str',\n",
    "  'tcp.flags.syn',\n",
    "  'tcp.hdr_len',\n",
    "  'tcp.len',\n",
    "  'tcp.nxtseq',\n",
    "  'tcp.srcport',\n",
    "  'tcp.stream',\n",
    "  'tcp.time_delta',\n",
    "  'tcp.time_relative',\n",
    "  'tcp.window_size',\n",
    "  'tcp.window_size_scalefactor',\n",
    "  'tcp.window_size_value',\n",
    "  'tls.record.length',\n",
    "  'udp.checksum.status',\n",
    "  'udp.dstport',\n",
    "  'udp.srcport',\n",
    "  'udp.time_delta',\n",
    "  'udp.time_relative',\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list={\"HPO\":['./small/AD-S1.csv','./small/AD-S2.csv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(model, params, x_train, y_train):\n",
    "    #grid = GridSearchCV(model, params, cv = ps, n_jobs = -1, scoring = score, verbose = 0, refit = False)\n",
    "    grid =RandomizedSearchCV(model, param_grid, cv=ps,scoring = 'f1_macro')\n",
    "    grid.fit(x_train, y_train)\n",
    "    return (grid.best_params_, round(grid.best_score_,8),grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))  \n",
    "            \n",
    "    return files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "HYPERPARAMETERS                     F1 Score             Time     No      \n",
      "default                             0.8715118027795188   4.301    24      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [03:44<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    criterion      max_depth    max_features    min_samples_split        F1        Std    Time    No  Attack\n",
      "--  -----------  -----------  --------------  -------------------  --------  ---------  ------  ----  --------\n",
      " 0  entropy               14              21                    5  0.905525  0.0309337   4.963    19  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['criterion', 'max_depth', 'max_features', 'min_samples_split', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "    print ('%-35s %-20s %-8s %-8s' % (\"HYPERPARAMETERS\",\"F1 Score\", \"Time\", \"No\"))\n",
    "\n",
    "    nfolds=10\n",
    "    param_grid = { 'criterion':['gini','entropy'],\n",
    "                      \"max_depth\":np.linspace(1, 32, 32, endpoint=True).astype(int),\n",
    "                     \"min_samples_split\": sp_randint(2,10),#uniform(0.1,1 ),\n",
    "                        # \"min_samples_leafs\" : np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "                        \"max_features\" : sp_randint(1,X_train.shape[1])}\n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=DecisionTreeClassifier()\n",
    "    for ii in range(25):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(50)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(DecisionTreeClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(10):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"DT_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['criterion', 'max_depth', 'max_features', 'min_samples_split', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "HYPERPARAMETERS                     F1 Score             Time     No      \n",
      "default                             0.9194501409800777   3.599    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [11:29<00:00, 68.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bootst    criter      max_depth    max_features    min_samp_split    n_estimators        F1         Std    Time    No  Attack\n",
      "--  --------  --------  -----------  --------------  ----------------  --------------  --------  ----------  ------  ----  --------\n",
      " 0  False     entropy            17               3                 5              71  0.921356  0.00149191  56.915     8  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print ('%-35s %-20s %-8s %-8s' % (\"HYPERPARAMETERS\",\"F1 Score\", \"Time\", \"No\"))\n",
    "\n",
    "\n",
    "\n",
    "    # use a full grid over all parameters\n",
    "    param_grid = {\"max_depth\":np.linspace(1, 32, 32, endpoint=True).astype(int),\n",
    "                  \"n_estimators\" : sp_randint(1, 200),\n",
    "                  \"max_features\": sp_randint(1, 11),\n",
    "                  \"min_samples_split\":sp_randint(2, 11),\n",
    "                  \"bootstrap\": [True, False],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=RandomForestClassifier()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(RandomForestClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"RF_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['bootst', 'criter', 'max_depth', 'max_features',\"min_samp_split\",\"n_estimators\", \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.9187501366691376   9.551    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [13:19<53:18, 799.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1100, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.2}        0.9186596865739023   799.564  0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [26:26<39:36, 792.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 900, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.05}        0.9176499913869687   786.89   1       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [40:24<27:06, 813.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 900, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.15}        0.9190143668224376   838.29   2       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [49:53<11:56, 716.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.15}        0.9182763764571321   568.267  3       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [1:03:14<00:00, 758.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 900, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.2}         0.9183814276663489   801.586  4       \n",
      "      n_estimators    min_child_weight    max_depth    learning_rate        F1          Std     Time    No  Attack\n",
      "--  --------------  ------------------  -----------  ---------------  --------  -----------  -------  ----  --------\n",
      " 0            1100                   3            5             0.2   0.91866   1.11022e-16  799.565     0  HPO\n",
      " 1             900                   3            3             0.05  0.91765   1.11022e-16  786.89      1  HPO\n",
      " 2             900                   1            3             0.15  0.919014  0            838.291     2  HPO\n",
      " 3             500                   1            5             0.15  0.918276  0            568.267     3  HPO\n",
      " 4             900                   1            5             0.2   0.918381  0            801.586     4  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_parametres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m     m\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m     77\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mm]  \n\u001b[1;32m---> 78\u001b[0m     \u001b[43mfinal_parametres\u001b[49m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mvalues)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     79\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame (final_parametres[\u001b[38;5;241m1\u001b[39m:], columns\u001b[38;5;241m=\u001b[39m  final_parametres[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m (tabulate(results, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(results\u001b[38;5;241m.\u001b[39mcolumns)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_parametres' is not defined"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "lines=[['n_estimators', 'min_child_weight', 'max_depth','learning_rate', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "\n",
    "\n",
    "    param_grid =   {\n",
    "    'n_estimators': [100, 500, 900, 1100, 1500],\n",
    "    'max_depth': [2, 3, 5, 10, 15],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.20],\n",
    "    'min_child_weight': [1, 2, 3, 4]\n",
    "    }\n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=xgboost.XGBClassifier()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(5)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(xgboost.XGBClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"XGB_HPO.csv\",index=False)\n",
    "\n",
    "\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "final_parametres=[['n_estimators', 'max_depth', 'learning_rate','min_child_weight', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      n_estimators   min_child_weight    max_depth     learning_rate     F1     Std     Time     No    Attack\n",
      "--  --------------   ----------------   -----------    ------------   --------  -----  -------  ----  --------\n",
      " 0      900                  1              3              0.15       0.919014    0    838.291   2     HPO\n"
     ]
    }
   ],
   "source": [
    "final_parametres=[['n_estimators', 'min_child_weight', 'max_depth','learning_rate', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"max_depth\"].min()\n",
    "    df=df[df[\"max_depth\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.8320865945922811   41.308   24      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [05:09<00:00, 30.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    algorithm      leaf_size    n_neighbors  weights         F1          Std    Time    No  Attack\n",
      "--  -----------  -----------  -------------  ---------  -------  -----------  ------  ----  --------\n",
      " 0  kd_tree               39              5  distance   0.83922  1.11022e-16  28.665     1  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['algorithm', 'leaf_size', 'n_neighbors', 'weights', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    \n",
    "\n",
    "    # use a full grid over all parameters\n",
    "    param_grid = {\"n_neighbors\" : sp_randint(1,64) ,  \n",
    "                 \"leaf_size\": sp_randint(1,50) , \n",
    "                  \"algorithm\" : [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                  \"weights\" : [\"uniform\", \"distance\"]}\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=KNeighborsClassifier()\n",
    "    for ii in range(25):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(KNeighborsClassifier(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"knn_HPO.csv\",index=False)\n",
    "\n",
    "final_parametres=[['algorithm', 'leaf_size', 'n_neighbors', 'weights', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    m=df[\"n_neighbors\"].min()\n",
    "    df=df[df[\"n_neighbors\"]==m]  \n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.4502714456827349   0.247    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:38<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      var_smoothing        F1    Std    Time    No  Attack\n",
      "--  ---------------  --------  -----  ------  ----  --------\n",
      " 0      1.87382e-08  0.460081      0   3.84      0  HPO\n",
      " 1      1.51991e-08  0.45918       0   3.811     1  HPO\n",
      " 2      1.23285e-09  0.451328      0   3.679     2  HPO\n",
      " 3      3.51119e-08  0.462366      0   3.847     3  HPO\n",
      " 4      5.3367e-09   0.458665      0   3.728     4  HPO\n",
      " 5      1.87382e-08  0.460081      0   3.927     5  HPO\n",
      " 6      1.51991e-06  0.472263      0   3.84      6  HPO\n",
      " 7      1e-06        0.468608      0   3.851     7  HPO\n",
      " 8      1.51991e-06  0.472263      0   3.907     8  HPO\n",
      " 9      3.51119e-08  0.462366      0   3.924     9  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[['var_smoothing', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    second=time()\n",
    "\n",
    "    param_grid = {\n",
    "        'var_smoothing': np.logspace(0,-9, num=100),\n",
    "    }\n",
    "\n",
    " \n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=GaussianNB()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(GaussianNB(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"NB_HPO.csv\",index=False)\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      var_smoothing        F1    Std    Time    No  Attack\n",
      "--  ---------------  --------  -----  ------  ----  --------\n",
      " 0      1.51991e-06  0.472263      0    3.84     6  HPO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_parametres=[[\"var_smoothing\",\"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.46100741599323264  4.483    0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [2:40:12<00:00, 961.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               C  penalty    Solver           F1    Std      Time    No  Attack\n",
      "--  ------------  ---------  ---------  --------  -----  --------  ----  --------\n",
      " 0   0.0809264    l2         newton-cg  0.766756      0  1124.27      0  HPO\n",
      " 1   0.108911     l2         newton-cg  0.765765      0  1329.36      1  HPO\n",
      " 2   0.000105309  l2         lbfgs      0.462433      0    30.318     2  HPO\n",
      " 3   9.12798e-05  l2         newton-cg  0.75582       0  1355.92      3  HPO\n",
      " 4   1.25843e-05  l2         newton-cg  0.766043      0  1305.28      4  HPO\n",
      " 5   0.408672     l2         newton-cg  0.766625      0  1704.81      5  HPO\n",
      " 6   4.80252      l2         liblinear  0.72965       0   253.894     6  HPO\n",
      " 7   0.262072     l2         newton-cg  0.763241      0  1305.79      7  HPO\n",
      " 8   4.40732e-05  l2         newton-cg  0.765857      0  1170.04      8  HPO\n",
      " 9  80.8929       l2         lbfgs      0.462941      0    33.227     9  HPO\n",
      "            C  penalty    Solver           F1    Std     Time    No  Attack\n",
      "--  ---------  ---------  ---------  --------  -----  -------  ----  --------\n",
      " 0  0.0809264  l2         newton-cg  0.766756      0  1124.27     0  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lines=[[\"C\",'penalty','Solver',  \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "    second=time()\n",
    "\n",
    "    param_grid = {\n",
    "     'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'C' : loguniform(1e-5, 100)\n",
    "        }\n",
    "    \n",
    "\n",
    " \n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=LogisticRegression()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(10)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(LogisticRegression(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(5):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        #print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"LR_HPO.csv\",index=False)\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "final_parametres=[[\"C\",'penalty','Solver',  \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "for i in results[\"Attack\"].unique():\n",
    "    df=results[results[\"Attack\"]==i]\n",
    "    m=df[\"F1\"].max()\n",
    "    df=df[df[\"F1\"]==m]\n",
    "    final_parametres.append(list(df.values)[0])\n",
    "results = pd.DataFrame (final_parametres[1:], columns=  final_parametres[0])\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV  SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO\n",
      "default                             0.22710681822174625  107.692  0       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [38:52<00:00, 2332.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.001, 'C': 1}                                                                   0.21965654231712956  2332.624 0       \n",
      "      gamma    C        F1    Std     Time    No  Attack\n",
      "--  -------  ---  --------  -----  -------  ----  --------\n",
      " 0    0.001    1  0.219657      0  2332.62     0  HPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lines=[[ 'gamma','C', \"F1\",\"Std\",\"Time\",\"No\",\"Attack\"]]\n",
    "\n",
    "\n",
    "for j in file_list:\n",
    "    print(j)\n",
    "    \n",
    "    \n",
    "    df=pd.read_csv(file_list[j][0],usecols=feature_list) \n",
    "    X_train = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_train=df['Label'].cat.codes  \n",
    "\n",
    "\n",
    "    df=pd.read_csv(file_list[j][1],usecols=feature_list) \n",
    "    X_test = df.iloc[:,0:-1]\n",
    "    df['Label'] = df['Label'].astype('category')\n",
    "    y_test=df['Label'].cat.codes  \n",
    "    \n",
    "    X= np.concatenate([X_train, X_test])\n",
    "    test_fold = [-1 for _ in range(X_train.shape[0])] + [0 for _ in range(X_test.shape[0])]\n",
    "    y = np.concatenate([y_train, y_test])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    \n",
    "\n",
    "\n",
    "    param_grid =  {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma' : [0.001, 0.01, 0.1, 1]}  \n",
    "\n",
    "    second=time()\n",
    "    f1=[]\n",
    "    clf=svm.SVC()\n",
    "    for ii in range(1):\n",
    "        clf.fit(X_train, y_train)\n",
    "        predict =clf.predict(X_test)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "    f1=sum(f1)/len(f1)   \n",
    "    #if f1>0.76:\n",
    "    print('%-35s %-20s %-8s %-8s' % (\"default\",f1,round(time()-second,3),ii))\n",
    "\n",
    "\n",
    "    \n",
    "    ######################################################################################################################\n",
    "    for i in tqdm(range(1)):\n",
    "        second=time()\n",
    "        a,b,clf=run_random_search(svm.SVC(),param_grid,X,y)\n",
    "        f1=[]\n",
    "        for ii in range(1):\n",
    "            clf.fit(X_train, y_train)\n",
    "            predict =clf.predict(X_test)\n",
    "            f1.append(sklearn.metrics.f1_score(y_test, predict,average= \"macro\") )\n",
    "        f1_result=sum(f1)/len(f1)   \n",
    "        f1=np.array(f1)\n",
    "        stndtd=f1.std()\n",
    "        temp=list(a.values())\n",
    "        print('%-90s %-20s %-8s %-8s' % (a,f1_result,round(time()-second,3),i))\n",
    "        temp=temp+[f1_result,stndtd,round(time()-second,3),i,j]\n",
    "        lines.append(temp)\n",
    "\n",
    "        #if f1>0.76:\n",
    "\n",
    "results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "results.to_csv(\"svm_HPO.csv\",index=False)\n",
    "\n",
    "\n",
    "print (tabulate(results, headers=list(results.columns)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown /s /t 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
