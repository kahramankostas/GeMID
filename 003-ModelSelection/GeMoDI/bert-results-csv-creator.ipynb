{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb5b2b7-61de-451f-aa06-080899a0b99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD-S1\n",
      "DI-S1\n",
      "DI-S1\n",
      "AD-S1\n",
      "AD-S1\n",
      "DI-S2\n",
      "DI-S2\n",
      "AD-S1\n",
      "AD-S2\n",
      "DI-S2\n",
      "DI-S2\n",
      "AD-S2\n",
      "AD-S2\n",
      "DI-S1\n",
      "DI-S1\n",
      "AD-S2\n",
      "Created file: BERT@AD-S1@DI-S1.csv\n",
      "Created file: BERT@DI-S1@AD-S1.csv\n",
      "Created file: BERT@AD-S1@DI-S2.csv\n",
      "Created file: BERT@DI-S2@AD-S1.csv\n",
      "Created file: BERT@AD-S2@DI-S2.csv\n",
      "Created file: BERT@DI-S2@AD-S2.csv\n",
      "Created file: BERT@AD-S2@DI-S1.csv\n",
      "Created file: BERT@DI-S1@AD-S2.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_metrics(text):\n",
    "    \"\"\"Parse training log text and extract relevant metrics.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Split text into different training sessions\n",
    "    sessions = text.strip().split(\"Train:\")\n",
    "    sessions = [s for s in sessions if s.strip()]\n",
    "    \n",
    "    for session in sessions:\n",
    "        # Extract file paths\n",
    "        lines = session.strip().split('\\n')\n",
    "        train_path = lines[0].split()[0].strip('./').replace('.csv', '')\n",
    "        test_path = lines[0].split('Test:')[1].strip().strip('./').replace('.csv', '')\n",
    "        train_path=train_path[-5:]\n",
    "        print(train_path)\n",
    "        test_path=test_path[-5:]\n",
    "        print(test_path)\n",
    "        # Extract accuracy\n",
    "        accuracy = float(re.search(r'Test Accuracy: (\\d+\\.\\d+)%', session).group(1)) / 100\n",
    "        \n",
    "        # Extract F1 score\n",
    "        f1_score = float(re.search(r'macro F1-Score: (\\d+\\.\\d+)', session).group(1))\n",
    "        \n",
    "        # Extract times\n",
    "        train_time = float(re.search(r'train_time: (\\d+\\.\\d+)', session).group(1))\n",
    "        test_time = float(re.search(r'test_time: (\\d+\\.\\d+)', session).group(1))\n",
    "        \n",
    "        # Create row\n",
    "        row = {\n",
    "            'Dataset': f'{train_path}@{test_path}',\n",
    "            'T': 0,\n",
    "            'CV': 1,\n",
    "            'ML': 'BERT',\n",
    "            'Acc': round(accuracy, 3),\n",
    "            'b_Acc': float('nan'),\n",
    "            'Prec': float('nan'),\n",
    "            'Rec': float('nan'),\n",
    "            'F1': round(f1_score, 4),\n",
    "            'kap': float('nan'),\n",
    "            'ROC': float('nan'),\n",
    "            'tra-T': round(train_time, 8),\n",
    "            'test-T': round(test_time, 7),\n",
    "            'Al-Time': 0\n",
    "        }\n",
    "        results.append(row)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_csv_files(input_text):\n",
    "    \"\"\"Create CSV files from the parsed metrics.\"\"\"\n",
    "    results = extract_metrics(input_text)\n",
    "    \n",
    "    for result in results:\n",
    "        # Create filename\n",
    "\n",
    "        \n",
    "        filename =f\"BERT@{result['Dataset']}.csv\"\n",
    "        \n",
    "        # Create DataFrame with single row\n",
    "        df = pd.DataFrame([result])\n",
    "        \n",
    "        # Save to CSV without index\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Created file: {filename}\")\n",
    "\n",
    "# Example usage\n",
    "with open('input.txt', 'r') as file:\n",
    "    log_text = file.read()\n",
    "    create_csv_files(log_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fa9702-c6d3-4ebe-8b54-0490804f88d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' ./small/AD-S1.csv Test: ./small/DI-S1.csv\\nEpoch [1/7], Loss: 1.6034\\nEpoch [2/7], Loss: 0.8258\\nEpoch [3/7], Loss: 0.6879\\nEpoch [4/7], Loss: 0.6282\\nEpoch [5/7], Loss: 0.5902\\nEpoch [6/7], Loss: 0.5551\\nEpoch [7/7], Loss: 0.5299\\ntrain_time: 13550.62489247322\\ntest_time: 946.7961132526398\\nmacro F1-Score: 0.5366\\nTest Accuracy: 54.30%\\n',\n",
       " ' ./small/DI-S1.csv Test: ./small/AD-S1.csv\\nEpoch [1/7], Loss: 1.7350\\nEpoch [2/7], Loss: 0.9516\\nEpoch [3/7], Loss: 0.8347\\nEpoch [4/7], Loss: 0.7852\\nEpoch [5/7], Loss: 0.7533\\nEpoch [6/7], Loss: 0.7191\\nEpoch [7/7], Loss: 0.6929\\ntrain_time: 13841.40567278862\\ntest_time: 255.47177910804749\\nmacro F1-Score: 0.6452\\nTest Accuracy: 64.25%']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
